% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{listings}
\lstdefinestyle{mystyle}{
	%backgroundcolor=\color{backcolour},   
	%commentstyle=\color{codegreen},
	%keywordstyle=\color{magenta},
	%numberstyle=\tiny\color{codegray},
	%stringstyle=\color{codepurple},
	basicstyle=\scriptsize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	%numbers=left,                    
	%numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2,
	%frame=single
}

\lstset{style=mystyle}

% ----------------------
% fancyref
\usepackage[plain]{fancyref}

\newcommand*{\fancyrefalglabelprefix}{alg}
\newcommand*{\fancyreflstlabelprefix}{lst}
\newcommand*{\fancyrefapplabelprefix}{app}

\fancyrefaddcaptions{english}{%
	\providecommand*{\frefalgname}{algorithm}%
	\providecommand*{\Frefalgname}{Algorithm}%
	%
	\providecommand*{\freflstname}{listing}%
	\providecommand*{\Freflstname}{Listing}%
	%
	\providecommand*{\frefappname}{appendix}%
	\providecommand*{\Frefappname}{Appendix}%
}%

\frefformat{plain}{\fancyrefalglabelprefix}{%
	\frefalgname\fancyrefdefaultspacing#1%
}%
\Frefformat{plain}{\fancyrefalglabelprefix}{%
	\Frefalgname\fancyrefdefaultspacing#1%
}
\frefformat{vario}{\fancyrefalglabelprefix}{%
	\frefalgname\fancyrefdefaultspacing#1#3%
}%
\Frefformat{vario}{\fancyrefalglabelprefix}{%
	\Frefalgname\fancyrefdefaultspacing#1#3%
}%

\frefformat{plain}{\fancyreflstlabelprefix}{%
	\freflstname\fancyrefdefaultspacing#1%
}%
\Frefformat{plain}{\fancyreflstlabelprefix}{%
	\Freflstname\fancyrefdefaultspacing#1%
}
\frefformat{vario}{\fancyreflstlabelprefix}{%
	\freflstname\fancyrefdefaultspacing#1#3%
}%
\Frefformat{vario}{\fancyreflstlabelprefix}{%
	\Freflstname\fancyrefdefaultspacing#1#3%
}%

\frefformat{plain}{\fancyrefapplabelprefix}{%
	\frefappname\fancyrefdefaultspacing#1%
}%
\Frefformat{plain}{\fancyrefapplabelprefix}{%
	\Frefappname\fancyrefdefaultspacing#1%
}
\frefformat{vario}{\fancyrefapplabelprefix}{%
	\frefappname\fancyrefdefaultspacing#1#3%
}%
\Frefformat{vario}{\fancyrefapplabelprefix}{%
	\Frefappname\fancyrefdefaultspacing#1#3%
}%


% line breaks in table cells:

\usepackage{makecell}
\renewcommand\cellalign{lt}


\captionsetup{compatibility=false}
%

\newcommand{\dummyfig}[3]{
	\centering
	\fbox{
		\begin{minipage}[c][#1\textheight][c]{#2\textwidth}
			\centering{#3}
		\end{minipage}
	}
}
\begin{document}
%
\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads

\mainmatter              % start of the contributions
%
\title{Bringing Back Structure to Free Text Email Conversations with Recurrent Neural Networks}
%
\titlerunning{Disentangling Email Conversations}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Tim Repke \and Ralf Krestel}
%
\authorrunning{Tim Repke et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Tim Repke, Ralf Krestel}
%
\institute{Hasso Plattner Institute, Potsdam, Germany\\
\email{(tim.repke|ralf.krestel)@hpi.de}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
The abstract should summarize the contents of the paper
using at least 70 and at most 150 words. It will be set in 9-point
font size and be inset 1.0 cm from the right and left margins.
There will be two blank lines before and after the Abstract. \dots
%\keywords{computational geometry, graph theory, Hamilton cycles}
\end{abstract}
%
\section{Introduction}
Emails are and important part of day to day business communication, hence their analysis inspired research from a variety of disciplines.
Many of those solely use information contained in the well structured email protocol headers, such as in Social Network Analysis, User Profiling, or Behaviour Analysis.

However, a lot more information remains hidden in the free text body of an email, which contains additional meta-data about a discussion in the form of quoted messages that are forwarded or replied to.
In the early days of email communication, users followed clear rules such as prefixing quoted text with angle brackets ($>$).
Nowadays though, due to the diversity of email programs, formatting standards, and the freedom to edit quoted text, identifying the different parts of a message body is a surprisingly challenging task.

We propose a neural network based approach and enable downstream tasks to utilise otherwise hidden or noisy information and overcome problems of error-prone rule-based approaches.
Further we show improvements in flexibility and performance over earlier work on similar tasks.





%früher: emails strukturiert, eingerückt, etc; heute: sehr frei/divers, geht nicht mehr mit regeln; Ansatz: deep learning

%ALTERNATIV:

%emails used for SNA, classification, behaviour, profiling, and more
%most based on full mails, but conversations contain quoted messaged including additional metadata; distracts downstream tasks

%our goal: clean up emails properly, don't assume full corpus, therefore keep all information

\subsection{Problem statement}
In this paper we propose methods to identify the inherent structure of free text email messages.
Components of an email are referred to as \textit{zones} similar to definition used by Lampert et al~\cite{zones}.
We assume, that text of a single email containing a discussion is represented as a sequence of headers and bodies, which is consistent with messages in the Enron corpus.

Hereby headers are blocks of meta-data automatically inserted by an email program, containing the sender, recipient, date, and subject.
Usually the header indicates, whether the subsequent message body was forwarded or replied to by the text above.
Bodies are the actual written messages, which on reply or forward are quoted below the newer message.

Message bodies are further separated into a \textit{greeting} (such as a formal or informal address of the recipient at the beginning of the message), \textit{authored text} (the actual message), \textit{signoff} (closing words of the message), and a \textit{signature} (containing contact information, advertising, or legal disclaimers).

Without loss of generality we consider exactly one zone type per line as exemplary shown in \Fref{fig:examplemail}.
In case of conflicts, the predominant or detailed type is used.


%describe task: split mails in different parts of the thread; parse meta information in intermediate headers
%- use term: zone
%- email as chain of header/body
%- within body: greetings, signoff, signature, text
%- header: contains metadata like from, to, when subject


\begin{figure}
\caption{Example Email}
\label{fig:examplemail}
% potential example listings:
% presto-k/discussion_threads/23.
% skilling-j/all_documents/1529.
% skilling-j/discussion_threads/1092.
\centering
\begin{tabular}{|c|}
	\hline 
	\begin{tabular}{lr}
		\makecell{
			\textit{From:} Alice\\ 
			\textit{To:} Bob, Brian\\
			\textit{Subject:} RE: Telephone Call with Jerry Murdock} &
		\textit{Sent:} Mon, 14 May 2001 07:15 AM
	\end{tabular}
	\\ 
	\hline 
	\begin{lstlisting}
	Thank you for your help.
	
	
	
	
	ISC Hotline
	03/15/2001 10:32 AM
	
	Sent by: Randi Howard
	To: Jeff Skilling/Corp/Enron@ENRON
	cc:  
	
	Subject: Re: My "P" Number  
	
	Mr. Skilling:
	
	Your P number is P00500599.  For your convenience, you can also go to 
	http://isc.enron.com/site/ under Site Highlights and reset your password or 
	find your "P" number.
	
	
	Thanks,
	
	Randi Howard
	ISC HOTLINE
	
	
	
	
	
	From:  Jeff Skilling                           03/15/2001 10:01 AM
	
	
	To: ISC Hotline/Corp/Enron@Enron
	cc:  
	
	Subject: My "P" Number
	
	Could you please forward my "P" number.  I am unable to get into the XMS 
	system and need this ASAP.
	
	Thanks for your help.
	\end{lstlisting}
	\\ 
	\hline 
\end{tabular} 
\end{figure}





\section{Related Work}
% structure outline
% 1. show some tasks where authors found, that cleaning bodies is needed
% 2. highlight previous tasks/approaches (aligning, extract first message, multi zone)
% 2.1 jamison et al, yeh et al
% 2.2 carvalho using cperceptron (collins)
% 2.3 lampert et al zoning + request for action (highlight improvements through zoning first)
%     similarly rauscher et al (knowledge zoning), estival et al (author profiling)

Email corpora provide fascinating insights into human communication behaviour and therefore inspire research in many different areas.
Datasets such as the Enron or Avocado corpus~\cite{avocado,enron} provide real world information about business communication and contain not only professional emails, but also personal emails as well as spam.
A recent survey provides a detailed overview of the multitude email classification tasks alone~\cite{classification}.
Similarly interesting is the analysis of communication networks based on meta-data such as senders, recipients, and time.

Models based on the written content of emails may get confused by automatically inserted text blocks or quoted messages.
Thus, working with real world data requires the need to normalise data prior to the problem at hand.
Rauscher et al. developed an approach to detect zones inside work-related emails where relevant business knowledge may be found~\cite{rauscher2015context}.
In their work towards detecting emails containing requests for action, Lampert et al. compare the performance of their model on full emails (which may contain quoted text) against the same emails after automatically removing quoted sections and managed to achieve a relative error reduction by 40\%~\cite{rfa}.
Similar observations were made more recently predicting reply behaviour within the Avocado dataset~\cite{replying}.

We identified two approaches in the literature on separating email zones.
Assuming a complete email corpus, with the email archives of all users, a message in the outbox of one user is found in the inbox of another.
Likewise, quoted messages exist within the corpus as an original message from preceding communication.
By finding overlapping text passages across the corpus, Jamison et al. managed to resolve email threads of the Enron corpus almost perfectly~\cite{headerless}.
It has to be noted, that the claimed accuracy of almost 100\% was only tested on 20 email threads.
In order to reassemble email threads, Yeh et al. considered a similar approach with a more elaborate evaluation reaching an accuracy of ??\%~\cite{similarity}.

In this paper, we don't assume a complete corpus to be able to extract all information from only a single email archive or even a single email.
Carvalho and Cohn proposed Jangada, a system to remove quoted text and signature blocks from emails in the 20 newsgroup dataset~\cite{signature,20news}.
They first classify emails to find those, that contain quoted text or signatures and then classify each line individually using Conditional Random Fields and Collin's Perceptrons~\cite{crf, cperceptron}.
Reported accuracies range from 97\% to above 99\%.
Those result could not be reproduced on our dataset and modified task.
Similar findings are confirmed by Estival et al., who measured an accuracy of around 64\% using Jangada on a different dataset~\cite{profiling}.
Using CRFs, they managed to extract five different zones (author text, signature, advertisement, quoted text and reply lines) with an average accuracy of up to88\%.

Most similar to our problem statement is the Zebra system by Lampert et al., which was developed for their previously mentioned work on requests for action~\cite{zones,rfa}.
The definition of zones is very similar to ours.
Contrary to our objectives, Zebra only tries to identify the zones within the very last message within an email thread and reject the rest as quoted text, whereas we aim to detect the zones across the entire email.
They describe graphic, orthographic, and lexical features to represent each line and classify line by line using an SVM reaching an average accuracy of 93\% on the two-zone task and 87\% on a nine-zone task.
It was found, that adding contextual features didn't improve the performance.
Comparing the performance by zone type, most problems are caused by signature lines (F-score around 60\%), signoffs (70\%) and attachements (69\%).

In our work we aim to improve upon those results, while providing a system that is able to detect zones along the entire conversation thread contained in an email and not only the first part.
This way even very small or incomplete datasets can be utilised for downstream tasks like social network analysis, speech acts and other classification tasks.


%\cite{rfa} (detecting request for action) works better with zoning (see \cite{zones}), removes noise and focuses on text itself (excluding signature etc)

%\cite{zones} "Zebra" detects nine different zones, only last email in thread is considered, rest is quoted, classifies lines individually with features using SVM, three zones with 0.91 accuracy, 9 zones 0.87 accuracy; context features didn't add improve performance

%\cite{profiling} don't describe much, uses CRF inspired by \cite{signature}, five categories (author text, signature, advertisement, quoted text, reply lines), for eval using three zones with accuracy 0.88, F1 0.9, compared with \cite{signature} 0.64 and 0.75 on their data

%\cite{signature} "Jangada" detects signature and reply lines, only considers the last $n$ lines, using CRF with 0.97 accuracy, CPerceptron with 0.989 accuracy; extraction task only performed on mails known to contain signatures! used 20 newsgroup dataset \cite{20news}

%\cite{headerless} look for overlaps in enron dataset to split mails into parts of the conversation; closest to our task; we don't consider full dataset though (looking at each mail individually); their goal is to then reassemble the conversation threads, tested on 20 threads (leading to 465 mails), claim accuracy approaching 100\%

%\cite{similarity} similar to \cite{headerless}

%[citation needed] previous social network analysis wrong, because not considering full picture

%\cite{workhard} overview of recent technologies applied to enron and avocado (personal business classification + SNA)

%\cite{replying} also recent, on avocado, reply behaviour, only "main header"

%\cite{enron} enron corpus

%\cite{avocado} avocado corpus

%[citation needed] shneiderman corpus

%\cite{20news} 20 newsgroups

\section{Segmentation of Emails}
describe an overview

\subsection{Representation of Email Data}
learn char or line embedding

\subsection{Classification of Email Lines}
continue training for classification into header/body

how to split thread based on that

\subsection{Extraction of Email Meta-Data}
continue training for further classification of body and header parts individually

\section{Experimental Setup}

\subsection{Dataset}
describe how data is selected from enron corpus (800: 500 train, 200 test, 100 eval)

annotated very detailed, even with some entity linking and signature parts, considered level of detail: header, body, signature, intro/outro; one annotator

some numbers comparing raw data and contained information in \Fref{tab:dataset}

\begin{table}
	\centering
	\caption{Experimental Results}
	\label{tab:dataset}
	\begin{tabular}{|c|ccc|}
		\hline
		Approach & Train & Test & Eval\\ \hline
		Raw Mails& 500 & 200 & 100\\
		Actual num mails & ? & ? & ? \\
		Avg Threadlen & ? & ? & ?\\
		signatures & ? & ? & ? \\
		people extracted (raw) & ?(?) & ?(?) & ?(?)\\
		\hline	
	\end{tabular}
\end{table}

\subsection{Competing Approaches}
baseline (regex+rules)

reimplement zebra\footnote{\url{http://zebra.thoughtlets.org/zoning.php}} and jangada\footnote{\url{http://www.cs.cmu.edu/~vitor/software/jangada/}}

describe differences, what needs to be changed to make it fair

RNN with features

show which task is more or less comparable between all

\subsection{Learning Model Parameters}

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\dummyfig{0.17}{0.9}{xaxis=perturbation, yaxis=accuracy, one line/boxplot} 
		\caption{Obfuscating test samples}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\dummyfig{0.17}{0.9}{xaxis=perturbation, yaxis=accuracy, three lines for different perturbation during eval} 
		\caption{Training with perturbation}
	\end{subfigure}
	\caption{Tolerance of the trained model against perturbation of the input}
\end{figure}

size of model/dimensions

size of training dataset (how much annotated data needed)

cross corpus (?)

\section{Results}
evaluate different complexities: full task (get all information), split head+body, additionally split body parts (sig, intro, outro)

results in \Fref{tab:results-comp} and \Fref{tab:results}

\begin{table}
	\centering
	\caption{Results of Two-Zone Task}
	\label{tab:results-comp}
	\begin{tabular}{|c|cc|}
		\hline
		Approach & Dataset& result\\ \hline
		We 1& a & 0.98\\
		We 2& a & 0.98\\
		We 3& a & 0.98\\
		Zebra\cite{zones} & d & 0.78\\
		Jangada\cite{signature} & d & 0.8\\
		\hline	
	\end{tabular}
\end{table}

\begin{table}
	\centering
	\caption{Experimental Results}
	\label{tab:results}
	\begin{tabular}{|c|cc|}
		\hline
		task & prec/rec& f1\\ \hline
		2zone& a & 0.98\\
		5zone& a & 0.98\\
		full& a & 0.98\\
		\hline	
	\end{tabular}
\end{table}

\Fref{fig:mpd} shows influence of extracting information vs using raw data

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\dummyfig{0.17}{0.9}{xaxis=timebuckets, yaxis=freq} 
		\caption{raw data}
	\end{subfigure}%
	~ 
	\begin{subfigure}[t]{0.5\textwidth}
		\centering
		\dummyfig{0.17}{0.9}{xaxis=timebuckets, yaxis=freq} 
		\caption{extracted data}
	\end{subfigure}
	\caption{Mail Frequency}
	\label{fig:mpd}
\end{figure}


maybe: email classification with+without splitting (i.e. try to classify folders)

\section{Conclusion and Future Work}
nicht nur für mails, auch forenthreads und andere semi-strukturierte daten



\bibliographystyle{splncs03}
\bibliography{biblio} 
\end{document}
