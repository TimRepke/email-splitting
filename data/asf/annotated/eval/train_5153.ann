{
  "wrapper": "plaintext",
  "text": "By following Chesney's recommendation we will hopefully uncover an SSL\nerror that is being masked.  Another thing to try is to disable hostname\nverification (it is enabled by default) to see whether the certificate is\nbeing rejected.\n\nOn Wed, Oct 4, 2017 at 5:15 AM, Chesnay Schepler <chesnay@apache.org> wrote:\n\n> something that would also help us narrow down the problematic area is to\n> enable SSL for one component at a time and see\n> which one causesd the job to fail.\n>\n>\n> On 04.10.2017 14:11, Chesnay Schepler wrote:\n>\n> The configuration looks reasonable. Just to be sure, are the paths\n> accessible by all nodes?\n>\n> As a first step, could you set the logging level to DEBUG (by modifying\n> the 'conf/log4j.properties' file), resubmit the job (after a cluster\n> restart) and check the Job- and TaskManager logs for any exception?\n>\n> On 04.10.2017 03:15, Aniket Deshpande wrote:\n>\n> Background: We have a setup of Flink 1.3.1 along with a secure MAPR\n> cluster (Flink is running on mapr client nodes). We run this flink cluster\n> via flink-jobmanager.sh foreground and flink-taskmanager.sh foreground command\n> via Marathon.  In order for us to make this work, we had to add\n> -Djavax.net.ssl.trustStore=\"$JAVA_HOME/jre/lib/security/cacerts\" in\n> flink-console.sh as extra JVM arg (otherwise, flink was taking MAPR's\n> ssl_truststore as default truststore and then we were facing issues for any\n> 3rd party jars like aws_sdk etc.). This entire setup was working fine as it\n> is and we could submit our jars and the pipelines ran without any problem\n>\n>\n> Problem: We started experimenting with enabling ssl for all communication\n> for Flink. For this, we followed https://ci.apache.\n> org/projects/flink/flink-docs-release-1.3/setup/security-ssl.html for\n> generating CA and keystore. I added the following properties to\n> flink-conf.yaml:\n>\n>\n> security.ssl.enabled: true\n> security.ssl.keystore: /opt/flink/certs/node1.keystore\n> security.ssl.keystore-password: <password>\n> security.ssl.key-password: <password>\n> security.ssl.truststore: /opt/flink/certs/ca.truststore\n> security.ssl.truststore-password: <password>\n> jobmanager.web.ssl.enabled: true\n> taskmanager.data.ssl.enabled: true\n> blob.service.ssl.enabled: true\n> akka.ssl.enabled: true\n>\n>\n> We then spin up a cluster and tried submitting the same job which was\n> working before. We get the following erros:\n> org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot load\n> user class: org.apache.flink.streaming.connectors.kafka.\n> FlinkKafkaConsumer09\n> ClassLoader info: URL ClassLoader:\n> Class not resolvable through given classloader.\n>         at org.apache.flink.streaming.api.graph.StreamConfig.\n> getStreamOperator(StreamConfig.java:229)\n>         at org.apache.flink.streaming.runtime.tasks.OperatorChain.<\n> init>(OperatorChain.java:95)\n>         at org.apache.flink.streaming.runtime.tasks.StreamTask.\n> invoke(StreamTask.java:230)\n>         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:702)\n>         at java.lang.Thread.run(Thread.java:748)\n>\n>\n> This error disappears when we remove the ssl config properties i.e run\n> flink cluster without ssl enabled.\n>\n>\n> So, did we miss any steps for enabling ssl?\n>\n>\n> P.S.: We tried removing the extra JVm arg mentioned above, but still get\n> the same error.\n>\n> --\n>\n> Aniket\n>\n>\n>\n>\n\n",
  "denotations": [
    {
      "id": 1,
      "start": 0,
      "end": 235,
      "text": "By following Chesney's recommendation we will hopefully uncover an SSL\nerror that is being masked.  Another thing to try is to disable hostname\nverification (it is enabled by default) to see whether the certificate is\nbeing rejected.\n\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 2,
      "start": 235,
      "end": 312,
      "text": "On Wed, Oct 4, 2017 at 5:15 AM, Chesnay Schepler <chesnay@apache.org> wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 3,
      "start": 312,
      "end": 478,
      "text": "\n> something that would also help us narrow down the problematic area is to\n> enable SSL for one component at a time and see\n> which one causesd the job to fail.\n>\n>\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 4,
      "start": 478,
      "end": 525,
      "text": "> On 04.10.2017 14:11, Chesnay Schepler wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 5,
      "start": 525,
      "end": 842,
      "text": ">\n> The configuration looks reasonable. Just to be sure, are the paths\n> accessible by all nodes?\n>\n> As a first step, could you set the logging level to DEBUG (by modifying\n> the 'conf/log4j.properties' file), resubmit the job (after a cluster\n> restart) and check the Job- and TaskManager logs for any exception?\n>\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 6,
      "start": 842,
      "end": 889,
      "text": "> On 04.10.2017 03:15, Aniket Deshpande wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 7,
      "start": 3319,
      "end": 3335,
      "text": "> --\n>\n> Aniket\n",
      "type": "Body/Signature",
      "meta": null
    },
    {
      "id": 8,
      "start": 889,
      "end": 3344,
      "text": ">\n> Background: We have a setup of Flink 1.3.1 along with a secure MAPR\n> cluster (Flink is running on mapr client nodes). We run this flink cluster\n> via flink-jobmanager.sh foreground and flink-taskmanager.sh foreground command\n> via Marathon.  In order for us to make this work, we had to add\n> -Djavax.net.ssl.trustStore=\"$JAVA_HOME/jre/lib/security/cacerts\" in\n> flink-console.sh as extra JVM arg (otherwise, flink was taking MAPR's\n> ssl_truststore as default truststore and then we were facing issues for any\n> 3rd party jars like aws_sdk etc.). This entire setup was working fine as it\n> is and we could submit our jars and the pipelines ran without any problem\n>\n>\n> Problem: We started experimenting with enabling ssl for all communication\n> for Flink. For this, we followed https://ci.apache.\n> org/projects/flink/flink-docs-release-1.3/setup/security-ssl.html for\n> generating CA and keystore. I added the following properties to\n> flink-conf.yaml:\n>\n>\n> security.ssl.enabled: true\n> security.ssl.keystore: /opt/flink/certs/node1.keystore\n> security.ssl.keystore-password: <password>\n> security.ssl.key-password: <password>\n> security.ssl.truststore: /opt/flink/certs/ca.truststore\n> security.ssl.truststore-password: <password>\n> jobmanager.web.ssl.enabled: true\n> taskmanager.data.ssl.enabled: true\n> blob.service.ssl.enabled: true\n> akka.ssl.enabled: true\n>\n>\n> We then spin up a cluster and tried submitting the same job which was\n> working before. We get the following erros:\n> org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot load\n> user class: org.apache.flink.streaming.connectors.kafka.\n> FlinkKafkaConsumer09\n> ClassLoader info: URL ClassLoader:\n> Class not resolvable through given classloader.\n>         at org.apache.flink.streaming.api.graph.StreamConfig.\n> getStreamOperator(StreamConfig.java:229)\n>         at org.apache.flink.streaming.runtime.tasks.OperatorChain.<\n> init>(OperatorChain.java:95)\n>         at org.apache.flink.streaming.runtime.tasks.StreamTask.\n> invoke(StreamTask.java:230)\n>         at org.apache.flink.runtime.taskmanager.Task.run(Task.java:702)\n>         at java.lang.Thread.run(Thread.java:748)\n>\n>\n> This error disappears when we remove the ssl config properties i.e run\n> flink cluster without ssl enabled.\n>\n>\n> So, did we miss any steps for enabling ssl?\n>\n>\n> P.S.: We tried removing the extra JVm arg mentioned above, but still get\n> the same error.\n>\n> --\n>\n> Aniket\n>\n>\n>\n>\n\n",
      "type": "Body",
      "meta": null
    }
  ],
  "meta": {},
  "id": "eval/train_5153"
}