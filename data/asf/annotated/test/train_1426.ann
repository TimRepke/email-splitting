{
  "wrapper": "text",
  "id": "test/train_1426",
  "meta": {},
  "text": "The following JIRA mentions that a fix made to read parquet 1.6.2 into\n2.X  STILL leaves an \"avalanche\" of warnings:\n\n\nhttps://issues.apache.org/jira/browse/SPARK-17993\n\nHere is the text inside one of the last comments before it was merged:\n\n  I have built the code from the PR and it indeed succeeds reading the data.\n  I have tried doing df.count() and now I'm swarmed with warnings like\nthis (they are just keep getting printed endlessly in the terminal):\n  16/08/11 12:18:51 WARN CorruptStatistics: Ignoring statistics\nbecause created_by could not be parsed (see PARQUET-251): parquet-mr\nversion 1.6.0\n  org.apache.parquet.VersionParser$VersionParseException: Could not\nparse created_by: parquet-mr version 1.6.0 using format: (.+) version\n((.*) )?\\(build ?(.*)\\)\n    at org.apache.parquet.VersionParser.parse(VersionParser.java:112)\n    at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:60)\n    at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:263)\n    at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:567)\n    at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:544)\n    at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:431)\n    at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:386)\n    at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:107)\n    at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:109)\n    at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$buildReader$1.apply(ParquetFileFormat.scala:369)\n    at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$buildReader$1.apply(ParquetFileFormat.scala:343)\n    at\n\nI am running 2.1.0 release and there are multitudes of these warnings.\nIs there any way - short of changing logging level to ERROR - to\nsuppress these?\n\n",
  "denotations": [
    {
      "id": 1,
      "start": 0,
      "end": 2194,
      "text": "The following JIRA mentions that a fix made to read parquet 1.6.2 into\n2.X  STILL leaves an \"avalanche\" of warnings:\n\n\nhttps://issues.apache.org/jira/browse/SPARK-17993\n\nHere is the text inside one of the last comments before it was merged:\n\n  I have built the code from the PR and it indeed succeeds reading the data.\n  I have tried doing df.count() and now I'm swarmed with warnings like\nthis (they are just keep getting printed endlessly in the terminal):\n  16/08/11 12:18:51 WARN CorruptStatistics: Ignoring statistics\nbecause created_by could not be parsed (see PARQUET-251): parquet-mr\nversion 1.6.0\n  org.apache.parquet.VersionParser$VersionParseException: Could not\nparse created_by: parquet-mr version 1.6.0 using format: (.+) version\n((.*) )?\\(build ?(.*)\\)\n    at org.apache.parquet.VersionParser.parse(VersionParser.java:112)\n    at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:60)\n    at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:263)\n    at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:567)\n    at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:544)\n    at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:431)\n    at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:386)\n    at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:107)\n    at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:109)\n    at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$buildReader$1.apply(ParquetFileFormat.scala:369)\n    at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$buildReader$1.apply(ParquetFileFormat.scala:343)\n    at\n\nI am running 2.1.0 release and there are multitudes of these warnings.\nIs there any way - short of changing logging level to ERROR - to\nsuppress these?\n\n",
      "type": "Body",
      "meta": null
    }
  ]
}