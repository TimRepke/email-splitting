{
  "wrapper": "plaintext",
  "text": "The trigger interval is optionally specified in the writeStream option\nbefore start.\n\nval windowedCounts = words.groupBy(\n  window($\"timestamp\", \"24 hours\", \"24 hours\"),\n  $\"word\"\n).count()\n.writeStream\n.trigger(ProcessingTime(\"10 seconds\"))  // optional\n.format(\"memory\")\n.queryName(\"tableName\")\n.start()\n\nSee the full example here -\nhttps://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n\n\nOn Mon, Apr 10, 2017 at 12:55 PM, kant kodali <kanth909@gmail.com> wrote:\n\n> Thanks again! Looks like the update mode is not available in 2.1 (which\n> seems to be the latest version as of today) and I am assuming there will be\n> a way to specify trigger interval with the next release because with the\n> following code I don't see a way to specify trigger interval.\n>\n> val windowedCounts = words.groupBy(\n>   window($\"timestamp\", \"24 hours\", \"24 hours\"),\n>   $\"word\").count()\n>\n>\n> On Mon, Apr 10, 2017 at 12:32 PM, Michael Armbrust <michael@databricks.com\n> > wrote:\n>\n>> It sounds like you want a tumbling window (where the slide and duration\n>> are the same).  This is the default if you give only one interval.  You\n>> should set the output mode to \"update\" (i.e. output only the rows that have\n>> been updated since the last trigger) and the trigger to \"1 second\".\n>>\n>> Try thinking about the batch query that would produce the answer you\n>> want.  Structured streaming will figure out an efficient way to compute\n>> that answer incrementally as new data arrives.\n>>\n>> On Mon, Apr 10, 2017 at 12:20 PM, kant kodali <kanth909@gmail.com> wrote:\n>>\n>>> Hi Michael,\n>>>\n>>> Thanks for the response. I guess I was thinking more in terms of the\n>>> regular streaming model. so In this case I am little confused what my\n>>> window interval and slide interval be for the following case?\n>>>\n>>> I need to hold a state (say a count) for 24 hours while capturing all\n>>> its updates and produce results every second. I also need to reset the\n>>> state (the count) back to zero every 24 hours.\n>>>\n>>>\n>>>\n>>>\n>>>\n>>>\n>>> On Mon, Apr 10, 2017 at 11:49 AM, Michael Armbrust <\n>>> michael@databricks.com> wrote:\n>>>\n>>>> Nope, structured streaming eliminates the limitation that\n>>>> micro-batching should affect the results of your streaming query.  Trigger\n>>>> is just an indication of how often you want to produce results (and if you\n>>>> leave it blank we just run as quickly as possible).\n>>>>\n>>>> To control how tuples are grouped into a window, take a look at the\n>>>> window\n>>>> <http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#window-operations-on-event-time>\n>>>> function.\n>>>>\n>>>> On Thu, Apr 6, 2017 at 10:26 AM, kant kodali <kanth909@gmail.com>\n>>>> wrote:\n>>>>\n>>>>> Hi All,\n>>>>>\n>>>>> Is the trigger interval mentioned in this doc\n>>>>> <http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html>\n>>>>> the same as batch interval in structured streaming? For example I have\na\n>>>>> long running receiver(not kafka) which sends me a real time stream I\nwant\n>>>>> to use window interval, slide interval of 24 hours to create the Tumbling\n>>>>> window effect but I want to process updates every second.\n>>>>>\n>>>>> Thanks!\n>>>>>\n>>>>\n>>>>\n>>>\n>>\n>\n\n",
  "denotations": [
    {
      "id": 1,
      "start": 0,
      "end": 486,
      "text": "The trigger interval is optionally specified in the writeStream option\nbefore start.\n\nval windowedCounts = words.groupBy(\n  window($\"timestamp\", \"24 hours\", \"24 hours\"),\n  $\"word\"\n).count()\n.writeStream\n.trigger(ProcessingTime(\"10 seconds\"))  // optional\n.format(\"memory\")\n.queryName(\"tableName\")\n.start()\n\nSee the full example here -\nhttps://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n\n\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 2,
      "start": 486,
      "end": 560,
      "text": "On Mon, Apr 10, 2017 at 12:55 PM, kant kodali <kanth909@gmail.com> wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 3,
      "start": 967,
      "end": 1055,
      "text": "> On Mon, Apr 10, 2017 at 12:32 PM, Michael Armbrust <michael@databricks.com\n> > wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 4,
      "start": 560,
      "end": 967,
      "text": "\n> Thanks again! Looks like the update mode is not available in 2.1 (which\n> seems to be the latest version as of today) and I am assuming there will be\n> a way to specify trigger interval with the next release because with the\n> following code I don't see a way to specify trigger interval.\n>\n> val windowedCounts = words.groupBy(\n>   window($\"timestamp\", \"24 hours\", \"24 hours\"),\n>   $\"word\").count()\n>\n>\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 5,
      "start": 1055,
      "end": 1560,
      "text": ">\n>> It sounds like you want a tumbling window (where the slide and duration\n>> are the same).  This is the default if you give only one interval.  You\n>> should set the output mode to \"update\" (i.e. output only the rows that have\n>> been updated since the last trigger) and the trigger to \"1 second\".\n>>\n>> Try thinking about the batch query that would produce the answer you\n>> want.  Structured streaming will figure out an efficient way to compute\n>> that answer incrementally as new data arrives.\n>>\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 6,
      "start": 1560,
      "end": 1637,
      "text": ">> On Mon, Apr 10, 2017 at 12:20 PM, kant kodali <kanth909@gmail.com> wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 7,
      "start": 1637,
      "end": 1656,
      "text": ">>\n>>> Hi Michael,\n",
      "type": "Body/Intro",
      "meta": null
    },
    {
      "id": 8,
      "start": 1637,
      "end": 2101,
      "text": ">>\n>>> Hi Michael,\n>>>\n>>> Thanks for the response. I guess I was thinking more in terms of the\n>>> regular streaming model. so In this case I am little confused what my\n>>> window interval and slide interval be for the following case?\n>>>\n>>> I need to hold a state (say a count) for 24 hours while capturing all\n>>> its updates and produce results every second. I also need to reset the\n>>> state (the count) back to zero every 24 hours.\n>>>\n>>>\n>>>\n>>>\n>>>\n>>>\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 9,
      "start": 2101,
      "end": 2193,
      "text": ">>> On Mon, Apr 10, 2017 at 11:49 AM, Michael Armbrust <\n>>> michael@databricks.com> wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 10,
      "start": 2193,
      "end": 2706,
      "text": ">>>\n>>>> Nope, structured streaming eliminates the limitation that\n>>>> micro-batching should affect the results of your streaming query.  Trigger\n>>>> is just an indication of how often you want to produce results (and if you\n>>>> leave it blank we just run as quickly as possible).\n>>>>\n>>>> To control how tuples are grouped into a window, take a look at the\n>>>> window\n>>>> <http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#window-operations-on-event-time>\n>>>> function.\n>>>>\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 11,
      "start": 2706,
      "end": 2789,
      "text": ">>>> On Thu, Apr 6, 2017 at 10:26 AM, kant kodali <kanth909@gmail.com>\n>>>> wrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 12,
      "start": 2789,
      "end": 2808,
      "text": ">>>>\n>>>>> Hi All,\n",
      "type": "Body/Intro",
      "meta": null
    },
    {
      "id": 13,
      "start": 3257,
      "end": 3277,
      "text": ">>>>>\n>>>>> Thanks!\n",
      "type": "Body/Outro",
      "meta": null
    },
    {
      "id": 14,
      "start": 2789,
      "end": 3303,
      "text": ">>>>\n>>>>> Hi All,\n>>>>>\n>>>>> Is the trigger interval mentioned in this doc\n>>>>> <http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html>\n>>>>> the same as batch interval in structured streaming? For example I have\na\n>>>>> long running receiver(not kafka) which sends me a real time stream I\nwant\n>>>>> to use window interval, slide interval of 24 hours to create the Tumbling\n>>>>> window effect but I want to process updates every second.\n>>>>>\n>>>>> Thanks!\n>>>>>\n>>>>\n>>>>\n>>>\n>>\n>\n\n",
      "type": "Body",
      "meta": null
    }
  ],
  "meta": {},
  "id": "test/train_2391"
}