{
  "wrapper": "plaintext",
  "text": "So, it turned out that i was not paying attention to the start parameter. I\nfound that the 'primary' node is asking for very large count of rows from\nshard nodes when the start= is a large value.\n\nOn Thu, Aug 17, 2017 at 11:28 AM, Nawab Zada Asad Iqbal <khichi@gmail.com>\nwrote:\n\n> Hi solr community\n>\n> I am having performance issues after solr6 upgrade. I have multiple nodes\n> in the cluster and direct queries to one of them with `shards=[list of\n> hosts]` which takes care of submitting queries to all the shards and\n> aggregating the results. All the original queries have rows=200.\n>\n> I have found that many logs with `distrib=false` have large rows value.\n> e.g., values like: 1200, 2200, 3200, 4200, ... .\n>\n> What is triggering it?  What am I doing wrong to cause this behavior.\n>\n>\n> Thanks in advance\n> Nawab\n>\n\n",
  "denotations": [
    {
      "id": 1,
      "start": 0,
      "end": 197,
      "text": "So, it turned out that i was not paying attention to the start parameter. I\nfound that the 'primary' node is asking for very large count of rows from\nshard nodes when the start= is a large value.\n\n",
      "type": "Body",
      "meta": null
    },
    {
      "id": 2,
      "start": 197,
      "end": 279,
      "text": "On Thu, Aug 17, 2017 at 11:28 AM, Nawab Zada Asad Iqbal <khichi@gmail.com>\nwrote:\n",
      "type": "Header",
      "meta": null
    },
    {
      "id": 3,
      "start": 279,
      "end": 300,
      "text": "\n> Hi solr community\n",
      "type": "Body/Intro",
      "meta": null
    },
    {
      "id": 4,
      "start": 792,
      "end": 822,
      "text": ">\n> Thanks in advance\n> Nawab\n",
      "type": "Body/Outro",
      "meta": null
    },
    {
      "id": 5,
      "start": 279,
      "end": 825,
      "text": "\n> Hi solr community\n>\n> I am having performance issues after solr6 upgrade. I have multiple nodes\n> in the cluster and direct queries to one of them with `shards=[list of\n> hosts]` which takes care of submitting queries to all the shards and\n> aggregating the results. All the original queries have rows=200.\n>\n> I have found that many logs with `distrib=false` have large rows value.\n> e.g., values like: 1200, 2200, 3200, 4200, ... .\n>\n> What is triggering it?  What am I doing wrong to cause this behavior.\n>\n>\n> Thanks in advance\n> Nawab\n>\n\n",
      "type": "Body",
      "meta": null
    }
  ],
  "meta": {},
  "id": "train/train_5528"
}