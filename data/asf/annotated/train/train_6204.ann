{
  "wrapper": "plaintext",
  "text": "Hello,\n\n\nBackground:\n\n\nWe have been successfully using Solr for over 5 years and we recently made the decision to\nmove into SolrCloud. For the most part that has been easy but we have repeated problems with\nour rolling restart were server remain functional but stay in Recovery until they stop trying.\nWe restarted because we increased the memory from 12GB to 16GB on the JVM.\n\n\nDoes anyone have any insight as to what is going on here?\n\nIs there a special procedure I should use for starting a stopping host?\n\nIs it ok to do a rolling restart on all the nodes in s shard?\n\n\nAny insight would be appreciated.\n\n\nConfiguration:\n\n\nWe have a group of servers with multiple collections. Each collection consist of one shard\nand multiple replicates. We are running the latest stable version of SolrClound 6.6 on Ubuntu\nLTS and Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 1.8.0_66 25.66-b17\n\n\n(collection)              (shard)          (replicates)\n\njournals_stage   ->  shard1  ->  solr-220 (leader) , solr-223, solr-221, solr-222 (replicates)\n\n\nProblem:\n\n\nRestarting the system puts the replicates in a recovery state they never exit from. They eventually\ngive up after 500 tries.  If I go to the individual replicates and execute a query the data\nis still available.\n\n\nUsing tcpdump I find the replicates sending this request to the leader (the leader appears\nto be active).\n\n\nThe exchange goes  like this - :\n\n\nsolr-220 is the leader.\n\nSolr-221 to Solr-220\n\n\n10:18:42.426823 IP solr-221:54341 > solr-220:8983:\n\n\nPOST /solr/journals_stage_shard1_replica1/update HTTP/1.1\nContent-Type: application/x-www-form-urlencoded; charset=UTF-8\nUser-Agent: Solr[org.apache.solr<http://org.apache.solr/>.client.solrj.impl<http://client.solrj.impl/>.HttpSolrClient]\n1.0\nContent-Length: 108\nHost: solr-220:8983\nConnection: Keep-Alive\n\n\ncommit_end_point=true&openSearcher=false&commit=true&softCommit=false&waitSearcher=true&wt=javabin&version=2\n\n\nSolr-220 back to Solr-221\n\n\nIP solr-220:8983 > solr-221:54341: Flags [P.], seq 1:5152, ack 385, win 235, options [nop,nop,\nTS val 858155553 ecr 858107069], length 5151\n..HTTP/1.1 500 Server Error\nContent-Type: application/octet-stream\nContent-Length: 5060\n\n\n.responseHeader..&statusT..%QTimeC.%error..#msg?.For input string: \"1578578283947098112\".%trace?.&java.lang.NumberFormatException:\nFor\ninput string: \"1578578283947098112\"\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat java.lang.Integer.parseInt(Integer.java:583)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat java.lang.Integer.parseInt(Integer.java:615)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.queries.function.docvalues.IntDocValues.getRangeScorer(IntDocValues.java:89)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.solr<http://org.apache.solr/>.search.function.ValueSourceRangeFilter$1.iterator(ValueSourceRangeFilter.java:83)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.solr<http://org.apache.solr/>.search.SolrConstantScoreQuery$ConstantWeight.scorer(SolrConstantScoreQuery.java:100)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.search.Weight.scorerSupplier(Weight.java:126)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.search.BooleanWeight.scorerSupplier(BooleanWeight.java:400)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:381)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.solr<http://org.apache.solr/>.update.DeleteByQueryWrapper$1.scorer(DeleteByQueryWrapper.java:90)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.index.BufferedUpdatesStream.applyQueryDeletes(BufferedUpdatesStream.java:709)\n\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:267)\n\n\n",
  "denotations": [
    {
      "id": 1,
      "start": 0,
      "end": 7,
      "text": "Hello,\n",
      "type": "Body/Intro",
      "meta": null
    },
    {
      "id": 2,
      "start": 0,
      "end": 3723,
      "text": "Hello,\n\n\nBackground:\n\n\nWe have been successfully using Solr for over 5 years and we recently made the decision to\nmove into SolrCloud. For the most part that has been easy but we have repeated problems with\nour rolling restart were server remain functional but stay in Recovery until they stop trying.\nWe restarted because we increased the memory from 12GB to 16GB on the JVM.\n\n\nDoes anyone have any insight as to what is going on here?\n\nIs there a special procedure I should use for starting a stopping host?\n\nIs it ok to do a rolling restart on all the nodes in s shard?\n\n\nAny insight would be appreciated.\n\n\nConfiguration:\n\n\nWe have a group of servers with multiple collections. Each collection consist of one shard\nand multiple replicates. We are running the latest stable version of SolrClound 6.6 on Ubuntu\nLTS and Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 1.8.0_66 25.66-b17\n\n\n(collection)              (shard)          (replicates)\n\njournals_stage   ->  shard1  ->  solr-220 (leader) , solr-223, solr-221, solr-222 (replicates)\n\n\nProblem:\n\n\nRestarting the system puts the replicates in a recovery state they never exit from. They eventually\ngive up after 500 tries.  If I go to the individual replicates and execute a query the data\nis still available.\n\n\nUsing tcpdump I find the replicates sending this request to the leader (the leader appears\nto be active).\n\n\nThe exchange goes  like this - :\n\n\nsolr-220 is the leader.\n\nSolr-221 to Solr-220\n\n\n10:18:42.426823 IP solr-221:54341 > solr-220:8983:\n\n\nPOST /solr/journals_stage_shard1_replica1/update HTTP/1.1\nContent-Type: application/x-www-form-urlencoded; charset=UTF-8\nUser-Agent: Solr[org.apache.solr<http://org.apache.solr/>.client.solrj.impl<http://client.solrj.impl/>.HttpSolrClient]\n1.0\nContent-Length: 108\nHost: solr-220:8983\nConnection: Keep-Alive\n\n\ncommit_end_point=true&openSearcher=false&commit=true&softCommit=false&waitSearcher=true&wt=javabin&version=2\n\n\nSolr-220 back to Solr-221\n\n\nIP solr-220:8983 > solr-221:54341: Flags [P.], seq 1:5152, ack 385, win 235, options [nop,nop,\nTS val 858155553 ecr 858107069], length 5151\n..HTTP/1.1 500 Server Error\nContent-Type: application/octet-stream\nContent-Length: 5060\n\n\n.responseHeader..&statusT..%QTimeC.%error..#msg?.For input string: \"1578578283947098112\".%trace?.&java.lang.NumberFormatException:\nFor\ninput string: \"1578578283947098112\"\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat java.lang.Integer.parseInt(Integer.java:583)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat java.lang.Integer.parseInt(Integer.java:615)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.queries.function.docvalues.IntDocValues.getRangeScorer(IntDocValues.java:89)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.solr<http://org.apache.solr/>.search.function.ValueSourceRangeFilter$1.iterator(ValueSourceRangeFilter.java:83)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.solr<http://org.apache.solr/>.search.SolrConstantScoreQuery$ConstantWeight.scorer(SolrConstantScoreQuery.java:100)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.search.Weight.scorerSupplier(Weight.java:126)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.search.BooleanWeight.scorerSupplier(BooleanWeight.java:400)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:381)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.solr<http://org.apache.solr/>.update.DeleteByQueryWrapper$1.scorer(DeleteByQueryWrapper.java:90)\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.index.BufferedUpdatesStream.applyQueryDeletes(BufferedUpdatesStream.java:709)\n\n\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201a\u00e2\u20ac\u201aat org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:267)\n\n\n",
      "type": "Body",
      "meta": null
    }
  ],
  "meta": {},
  "id": "train/train_6204"
}